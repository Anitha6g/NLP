# -*- coding: utf-8 -*-
"""Machine_Generated_News_Dataset_creation_without_cosine_1608.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qcgY3uLjwuHbXwelN9EOFcRtjf89pMOd

# **Machine Generated Fake & Real news dataset creation**
"""

from google.colab import drive
drive.mount('/content/drive', force_remount=True)

"""# **Importing and Installation.**"""

# Importing necessary libraries
import pandas as pd
import json
import numpy as np
import re
import nltk
from nltk.corpus import stopwords
nltk.download('stopwords')

from sklearn.feature_extraction.text import CountVectorizer

pip install googletrans

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/drive/My Drive/Colab Notebooks

"""# **Preprocessing function for text articles.**"""

# Extracting set of stopwords from nltk libraries
stop_words = set(stopwords.words('english'))

# Function to preprocess the news articles. Tokenize, lower, expand contactions, lemmatize, remove punctuation, numbers and stop words
def pre_process(_data):
    _data = _data.lower()
    def clean_words(s):
        s = re.sub(r'^(https|http)?:\/\/(\w|\.|\/|\?|\=|\&|\%)*\b', '', s)
        s = re.sub(r'[0-9]+', '', s)
        s = re.sub(r'@\w+','',s)
        return re.sub(r'[^A-Za-z ]+', '', s)

    tokens = _data.split(" ")
    tokens = list(map(clean_words,tokens))
    tokens = [w for w in tokens if not w in stop_words] 

    return " ".join(tokens)

"""# **Reading and constructing the dataset containing machine generated fake article based on real articles.**"""

# Loading the machine generated dataset containing fake news through pandas
fake_news_data = pd.read_json('/content/drive/My Drive/Colab Notebooks/Machine_generated_news_5053.jsonl', lines = True, encoding="utf8")
fake_news_data

"""**Machine generated Fake articles**"""

# Rearranging and structuring the data based on feature requirement
cols = ['text','gens_article']
fake_news_data_new = fake_news_data[cols]
fake_news_data_new.columns = ['Ground_Truth', 'Machine_Generated_Article']

fake_news_data_new['Machine_Generated_Article'] = [' '.join(map(str, l)) for l in fake_news_data_new['Machine_Generated_Article']]
fake_news_data_new.head()

# Applying the preprocessing function to the news articles. Tokenize, lower, expand contactions, lemmatize, remove punctuation, numbers and stop words
fake_news_data_new['Ground_Truth'] = fake_news_data_new['Ground_Truth'].apply(lambda x:pre_process(x))
fake_news_data_new['Machine_Generated_Article'] = fake_news_data_new['Machine_Generated_Article'].apply(lambda x:pre_process(x))
fake_news_data_new.head()

# Labelling the artciles as fake based on the way it is generated.
fake_news_data_new["is_similar"] = 0
fake_news_data_new

"""# **Cosine similarity to find similarity score between real news and neural fake news.**"""

#function to evaluate the cosine similarity score
def cosine_distance_countvectorizer_method(s1, s2):
    
    # sentences to list
    allsentences = [s1 , s2]
    
    # packages
    from sklearn.feature_extraction.text import CountVectorizer
    from scipy.spatial import distance
    
    # text to vector
    vectorizer = CountVectorizer()
    all_sentences_to_vector = vectorizer.fit_transform(allsentences)
    text_to_vector_v1 = all_sentences_to_vector.toarray()[0].tolist()
    text_to_vector_v2 = all_sentences_to_vector.toarray()[1].tolist()
    
    # distance of similarity
    cosine = distance.cosine(text_to_vector_v1, text_to_vector_v2)
    #print('Similarity of two sentences are equal to ',round((1-cosine)*100,2),'%')
    simsc = round((1-cosine)*100,2)
    return simsc

#Example 1
score_1 = cosine_distance_countvectorizer_method(fake_news_data_new['Ground_Truth'].iloc[70],fake_news_data_new['Machine_Generated_Article'].iloc[70])
print("The similatity of the article is:", score_1)

#Example 1
score_2 = cosine_distance_countvectorizer_method(fake_news_data_new['Ground_Truth'].iloc[500],fake_news_data_new['Machine_Generated_Article'].iloc[500])
print("The similatity of the article is:", score_2)

sim_score = []
for i in range(fake_news_data_new.shape[0]):
    score = cosine_distance_countvectorizer_method(fake_news_data_new['Ground_Truth'].iloc[i],fake_news_data_new['Machine_Generated_Article'].iloc[i])
    sim_score.append(score)
fake_news_data_new['Similarity_Score'] = sim_score
fake_news_data_new.loc[fake_news_data_new['Similarity_Score'] <= 50, 'pred_similar'] = '0'
fake_news_data_new.loc[fake_news_data_new['Similarity_Score'] > 50, 'pred_similar'] = '1'
fake_news_data_new['pred_similar'].replace(np.nan, 0, inplace=True)
fake_news_data_new

fake_news_data_new.to_csv(r'/content/drive/My Drive/Colab Notebooks/fake_news_data_new.csv', header=True)

"""# **MSE**"""

# Loading the machine generated dataset containing fake news through pandas
fake_news_mse = pd.read_csv('/content/drive/My Drive/Colab Notebooks/fake_news_data_new.csv', encoding="utf8")
fake_news_mse

#converting numpy array to list
y_true_list = fake_news_mse['is_similar'].tolist()
y_pred_list = fake_news_mse['pred_similar'].tolist()

#calculating mean squared error
from sklearn.metrics import mean_squared_error
mean_squared_error(y_true_list, y_pred_list)

#calculating mean squared log error
from sklearn.metrics import mean_squared_log_error
mean_squared_log_error(y_true_list, y_pred_list)

# Loading the machine generated dataset containing real news through pandas
real_news_mse = pd.read_csv('/content/drive/My Drive/Colab Notebooks/real_news_data_new.csv', encoding="utf8")
real_news_mse

#Evaluating the cosine similrity score between the real news and neural real news
sim_score_r = []
for i in range(real_news_mse.shape[0]):
    score_r = cosine_distance_countvectorizer_method(real_news_mse['Ground_Truth'].iloc[i],real_news_mse['Machine_Generated_Article'].iloc[i])
    sim_score_r.append(score_r)
real_news_mse['Similarity_Score'] = sim_score_r
real_news_mse.loc[real_news_mse['Similarity_Score'] <= 50, 'pred_similar'] = '0'
real_news_mse.loc[real_news_mse['Similarity_Score'] > 50, 'pred_similar'] = '1'
real_news_mse['pred_similar'].replace(np.nan, 0, inplace=True)
real_news_mse

#converting numpy array to list
y_true_r = real_news_mse['Machine_News_Labels'].tolist()
y_pred_r = real_news_mse['pred_similar'].tolist()

#converting the column to int
for i in range(0, len(y_pred_r)): 
    y_pred_r[i] = int(y_pred_r[i])

#calculating mean squared error
from sklearn.metrics import mean_squared_error
mean_squared_error(y_true_r, y_pred_r)

#calculating mean squared log error
from sklearn.metrics import mean_squared_log_error
mean_squared_log_error(y_true_r, y_pred_r)

"""# **Data Augmentation using Translator API for creating Machine generated real news.**"""

# Loading the machine generated dataset containing fake news through pandas

real_news_data = pd.read_json('/content/drive/My Drive/Colab Notebooks/Real_News_untouched_for_data_augmentation.JSONL', lines = True, encoding="utf8")
real_news_data.head()

# Rearranging and structuring the data based on feature requirement
r_cols = ['title', 'text']
real_news_data_new = real_news_data[r_cols]
real_news_data_new.columns = ['Title', 'Text']

real_news_data_new.head()

real_news_data_new['Ground_Truth'] = real_news_data_new['Title'] + real_news_data_new['Text']
real_news_data_new

real_news_data_new1 = real_news_data_new.drop(real_news_data_new.loc[:, 'Title':'Text'].columns, axis = 1) 
real_news_data_new1

# Applying the preprocessing function to the news articles. Tokenize, lower, expand contactions, lemmatize, remove punctuation, numbers and stop words
real_news_data_new1['Ground_Truth'] = real_news_data_new1['Ground_Truth'].apply(lambda x:pre_process(x))

real_news_data_new1['Ground_Truth']

ground_true_list = real_news_data_new1['Ground_Truth'].tolist()

ground_true_list[0]

from googletrans import Translator
translator = Translator()
translations_lang = translator.translate(ground_true_list, dest='de')
trans_lang = []
for translation in translations_lang:
  #print(translation.origin, ' -> ', translation.text)
  trans_lang.append(translation.text)

print(trans_lang)

trans_eng = []
tranlation_eng = translator.translate(trans_lang, dest = 'en')
for translate_en in tranlation_eng:
  #print(translate_en.text)
  trans_eng.append(translate_en.text)

data_aug_df = pd.DataFrame(trans_eng, columns = ['Machine_Generated_Article'])
data_aug_df['Ground_Truth'] = real_news_data_new['Ground_Truth']
columns_titles = ["Ground_Truth","Machine_Generated_Article"]
data_aug_df=data_aug_df.reindex(columns=columns_titles)
data_aug_df["is_similar"] = 1
data_aug_df

data_aug_df['Ground_Truth'] = data_aug_df['Ground_Truth'].apply(lambda x:pre_process(x))
data_aug_df['Machine_Generated_Article'] = data_aug_df['Machine_Generated_Article'].apply(lambda x:pre_process(x))
#show the first 'text'
data_aug_df

dreal_texts = list()

for dtext in data_aug_df['Ground_Truth']:
  dreal_texts.append(dtext)
dreal_texts

dfake_texts = list()

for dtext1 in data_aug_df['Machine_Generated_Article']:
  dfake_texts.append(dtext1)
#dfake_texts

#Preprocessing the text - Word tokenizaion and lowercasing
dreal_vocab = set()
dfake_vocab = set()

for in_sentence in dreal_texts:
  in_texts = [in_word.lower() for in_word in in_sentence.split()]
  for in_i in in_texts:
    dreal_vocab.add(in_i)
for out_sentence in dfake_texts:
  out_texts = [out_word.lower() for out_word in out_sentence.split()]
  for out_i in out_texts:
    dfake_vocab.add(out_i)
print(len(dfake_vocab))

#Source text tokenizing
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.utils import to_categorical

dinput_tokenizer = Tokenizer(num_words=len(dreal_texts))
dinput_tokenizer.fit_on_texts(dreal_texts)
dinput_integer_seq = dinput_tokenizer.texts_to_sequences(dreal_texts)

word2idx_inputs = dinput_tokenizer.word_index
dmax_real_seq_length = max([len(txt) for txt in dinput_integer_seq])
dmax_real_seq_length

#Target text tokenizing
doutput_tokenizer = Tokenizer(num_words=len(dfake_texts))
doutput_tokenizer.fit_on_texts(dfake_texts)
doutput_integer_seq = doutput_tokenizer.texts_to_sequences(dfake_texts)
                                                           
word2idx_outputs = doutput_tokenizer.word_index
dmax_fake_seq_length = max([len(txt) for txt in doutput_integer_seq])
dmax_fake_seq_length

#Printing real and fake text details
dnum_real_tokens = len(dreal_vocab)
dnum_fake_tokens = len(dfake_vocab)

print('Number of news articles:', len(dreal_texts))
print('Number of unique tokens in real news article:', dnum_real_tokens)
print('Number of unique tokens in machine generated fake news article:', dnum_fake_tokens)
print('Length of longest real news artice:', dmax_real_seq_length)
print('Length of longest machine generated fake news article:', dmax_fake_seq_length)

"""# **Final dataset**"""

fake_news_data_new

frames = [fake_news_data_new, data_aug_df]

merged_DF = pd.concat(frames,ignore_index=True)
merged_DF

merged_DF_new = merged_DF
merged_DF_new

merged_DF_new1 = merged_DF_new.rename(columns={"is_similar": "Machine_News_Labels"})
merged_DF_new1

merged_DF_new1['Machine_Generated_Article'].replace('', np.nan, inplace=True)

merged_DF_new1.dropna(subset=['Machine_Generated_Article'], inplace=True)
merged_DF_new1

#https://www.dataquest.io/blog/machine-learning-preparing-data/
import matplotlib.pyplot as plt
import seaborn as sns
# pallete = (0.1,0.2,0.5)
fig, axs = plt.subplots(1,2,figsize=(14,7))
sns.countplot(x='Machine_News_Labels',data=merged_DF_new1,ax=axs[0])
axs[0].set_title("Frequency of machine generate news(0(fake),1(real))")
merged_DF_new1.Machine_News_Labels.value_counts().plot(x=None,y=None, kind='pie', ax=axs[1],autopct='%1.2f%%')
axs[1].set_title("Percentage of machine generate news(0(fake),1(real))")
plt.show()

merged_DF_new1.to_csv(r'/content/drive/My Drive/Colab Notebooks/final_dataset.csv', header=True)

"""# **Semantic Textual Similarity(STS) using Manhattan Siamese LSTM Neural Nets.**"""

import sys
sys.path.append('/content/drive/My \Drive/Colab Notebooks/lstm-siamese-text-similarity-master')

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
# %pwd

import os
os.chdir("/content/drive/My Drive/Colab Notebooks/lstm-siamese-text-similarity-master")

from model import SiameseBiLSTM
from inputHandler import word_embed_meta_data, create_test_data
from config import siamese_config
import pandas as pd

############ Data Preperation ##########
import pandas as pd
df = pd.read_csv('/content/drive/My Drive/Colab Notebooks//final_dataset.csv')

sentences1 = list(df['Ground_Truth'])
sentences2 = list(df['Machine_Generated_Article'])
is_similar = list(df['Machine_News_Labels'])
del df

######## Word Embedding ############

tokenizer, embedding_matrix = word_embed_meta_data(sentences1 + sentences2,  siamese_config['EMBEDDING_DIM'])

embedding_meta_data = {
	'tokenizer': tokenizer,
	'embedding_matrix': embedding_matrix
}

## creating sentence pairs
sentences_pair = [(x1, x2) for x1, x2 in zip(sentences1, sentences2)]
del sentences1
del sentences2

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(sentences_pair, is_similar, test_size=0.20, shuffle = True,random_state = 42)

len(X_test)

######## Training ########

class Configuration(object):
    """Dump stuff here"""

CONFIG = Configuration()

CONFIG.embedding_dim = siamese_config['EMBEDDING_DIM']
CONFIG.max_sequence_length = siamese_config['MAX_SEQUENCE_LENGTH']
CONFIG.number_lstm_units = siamese_config['NUMBER_LSTM']
CONFIG.rate_drop_lstm = siamese_config['RATE_DROP_LSTM']
CONFIG.number_dense_units = siamese_config['NUMBER_DENSE_UNITS']
CONFIG.activation_function = siamese_config['ACTIVATION_FUNCTION']
CONFIG.rate_drop_dense = siamese_config['RATE_DROP_DENSE']
CONFIG.validation_split_ratio = siamese_config['VALIDATION_SPLIT']

siamese = SiameseBiLSTM(CONFIG.embedding_dim , CONFIG.max_sequence_length, CONFIG.number_lstm_units , CONFIG.number_dense_units, CONFIG.rate_drop_lstm, CONFIG.rate_drop_dense, CONFIG.activation_function, CONFIG.validation_split_ratio)

best_model_path, hist = siamese.train_model(X_train, y_train, embedding_meta_data, model_save_directory='./')

from operator import itemgetter
from keras.models import load_model

model = load_model(best_model_path)

model.summary()

print(hist.history.values())

valid_acc_1 = hist.history['val_acc']
valid_acc_1

#Plot for Model Accuracy
import keras
from matplotlib import pyplot as plt
#history = model1.fit(train_x, train_y,validation_split = 0.1, epochs=50, batch_size=4)
#plt.plot(hist.history['acc'])
plt.plot(hist.history['val_acc'])
plt.title('Learning Curve - Model Accuracy')
plt.ylabel('Validation accuracy Rate')
plt.xlabel('Number of epoch')
#plt.legend(['Train_score', 'Val_score'], loc='lower right')
plt.show()

#Plot for Model Loss
import keras
from matplotlib import pyplot as plt
#history = model1.fit(train_x, train_y,validation_split = 0.1, epochs=50, batch_size=4)
#plt.plot(hist.history['loss'])
plt.plot(hist.history['val_loss'])
plt.title('Learning Curve - Model Loss')
plt.ylabel('Validation loss Rate')
plt.xlabel('Number of epoch')
#plt.legend(['Train_score', 'Val_score'], loc='upper right')
plt.show()

import numpy as np

preds_label = []
test_data_x1_arrs = np.empty((0,10))
test_data_x2_arrs = np.empty((0,10))
leaks_test_arrs = np.empty((0,3))
for i in range(len(X_test)):
  test_sentence_pairs = [(X_test[i])]
  test_data_x1, test_data_x2, leaks_test = create_test_data(tokenizer, test_sentence_pairs, siamese_config['MAX_SEQUENCE_LENGTH'])

  test_data_x1_arrs = np.vstack((test_data_x1_arrs, test_data_x1))
  test_data_x2_arrs = np.vstack((test_data_x2_arrs, test_data_x2))
  leaks_test_arrs = np.vstack((leaks_test_arrs, leaks_test))

  preds = list(model.predict([test_data_x1, test_data_x2, leaks_test]).ravel())
  for i in preds:
    if i >= 0.70:
      preds_label.append(1)
    elif i < 0.70:
      preds_label.append(0)
  results = [(x, y, z, l) for (x, y), z, l in zip(test_sentence_pairs, preds, preds_label)]
  results.sort(key=itemgetter(2), reverse=True)
  #print(results)

y_test = np.array(y_test)
type(y_test)

#Code to evaluate model,Accuracy is  89% on validation dataset
loss, acc = model.evaluate([test_data_x1_arrs, test_data_x2_arrs, leaks_test_arrs], y_test)
print('Test Accuracy: {}'.format(acc))
print('Test Loss: {}'.format(loss))

import numpy as np
from sklearn.metrics import precision_recall_fscore_support
prf = precision_recall_fscore_support(y_test, preds_label, average='macro')
prec, rec, fscore, val = prf
print("Precision rate for the Siamese LSTM semantic textual similarity model to detect neural fake news is:", prec)
print("Recall rate for the Siamese LSTM semantic textual similarity model to detect neural fake news is:", rec)
print("F1 Score for the Siamese LSTM semantic textual similarity model to detect neural fake news is:", fscore)

from sklearn.metrics import confusion_matrix 
import seaborn as sb
''' Confusion matrix for predicted Real and Fake articles in test dataset'''
Variety = ['Real_Article','Fake_Article']
conf_matrix = confusion_matrix(y_test, preds_label)
Hm = sb.heatmap(conf_matrix, annot = True, fmt=".0f",xticklabels = Variety, yticklabels = Variety);
Hm.set(xlabel='True Value', ylabel='Predicted Value')
Hm.set_title('Confusion matrix for predicted Real and Fake articles in test dataset')

#pd.DataFrame.plot.pie(y='Confusion_Matrix')
import matplotlib.pyplot as plt
import pylab

# title.set_ha("left")
# plt.gca().axis("equal")

labels = ['True Pos', 'True Neg', 'False Neg', 'False Pos']
df = pd.DataFrame({'Confusion_Matrix': [436, 808, 193, 575]},
                  index=['True Positive', 'True Negative', 'False Negative', 'False Positive'])
plot = df.plot.pie(y='Confusion_Matrix', autopct = "%.2f%%",figsize=(5, 5), explode = (0, 0, 0, 0),colors = ['lightseagreen', 'mediumturquoise','turquoise','aquamarine'])
pylab.ylabel('')
title = plt.title('Confusion Matrix', fontsize=18)
plot.legend(loc="center right", bbox_to_anchor=(3,0.7), fontsize=10)
plt.tight_layout()
#plt.subplots_adjust(left=0.0, bottom=0.1, right=0.45)